# Abusive Comment Detection Model

This GitHub repository contains the dataset and training code required to build an abusive comment detection model.

---

## About

This project is focused on detecting abusive or toxic comments using machine learning techniques. The model can classify comments as either:
- Abusive (False)
- Non-Abusive (True)

---

## Note

> *This repository only contains the dataset and training code. You can use this code to create and train your own model.*

- No pre-trained model is provided.
- You can modify the code, experiment with the data, and build your own custom abusive comment detection model.

---

## Contents

- `dataset/` → Dataset files (CSV/Text format)
- `train.py` → Training script to train your model
- `README.md` → Project details

---

## Usage

1. Clone this repository:
```bash
git clone https://github.com/SanthoshMB08/Absue-detection-ai.git
